import streamlit as st
import pandas as pd
import numpy as np
import requests
import os
import re
import urllib3
from datetime import datetime
import glob
import time
import zipfile
import collections

# --- 1. ç³»çµ±è¨­å®š ---
st.set_page_config(
    page_title="å°å½©æ•¸æ“šä¸­å¿ƒ v27.0 (çµ•å°æ­¸æª”ç‰ˆ)", 
    page_icon="ğŸ—„ï¸", 
    layout="wide",
    initial_sidebar_state="expanded"
)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- 2. è³‡æ–™è·¯å¾‘ ---
DATA_DIR = "data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# é æ¸¬ç´€éŒ„æª”
LOG_FILE = os.path.join(DATA_DIR, "prediction_log.csv")

# --- 3. éŠæˆ²è¨­å®š (åªä¿ç•™ä¸‰å¤§å¤©ç‹) ---
GAME_CONFIG = {
    "ä»Šå½©539": {
        "keywords": ["ä»Šå½©539", "539"],
        "db_file": os.path.join(DATA_DIR, "db_539.csv"),
        "num_count": 5, "num_range": (1, 39), "has_special": False, 
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "Source"]
    },
    "å¤§æ¨‚é€": {
        "keywords": ["å¤§æ¨‚é€", "Lotto649"],
        "db_file": os.path.join(DATA_DIR, "db_lotto649.csv"),
        "num_count": 6, "num_range": (1, 49), "has_special": True,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "N6", "SP", "Source"]
    },
    "å¨åŠ›å½©": {
        "keywords": ["å¨åŠ›å½©", "SuperLotto"],
        "db_file": os.path.join(DATA_DIR, "db_super.csv"),
        "num_count": 6, "num_range": (1, 38), "has_special": True, "special_is_zone2": True, "special_range": (1, 8),
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "N6", "Zw", "Source"]
    }
}

# --- 4. æ ¸å¿ƒåŠŸèƒ½ï¼šå¼·åŠ›è§£æèˆ‡æ­¸æª” ---

def parse_date_strict(date_val):
    """å¼·åŠ›æ—¥æœŸè§£æï¼šæ”¯æ´ æ°‘åœ‹å¹´/è¥¿å…ƒå¹´/æ–œç·š/æ©«ç·š"""
    d_str = str(date_val).strip()
    # 1. å˜—è©¦æ¨™æº– YYYY-MM-DD
    try:
        return pd.to_datetime(d_str).strftime('%Y-%m-%d')
    except:
        pass
    
    # 2. å˜—è©¦æ°‘åœ‹å¹´ (e.g. 112/01/01, 96/1/1)
    # æŠ“å– 2-3ä½å¹´, 1-2ä½æœˆ, 1-2ä½æ—¥
    match = re.match(r'(\d{2,3})[/-](\d{1,2})[/-](\d{1,2})', d_str)
    if match:
        y = int(match.group(1))
        m = int(match.group(2))
        d = int(match.group(3))
        # è½‰è¥¿å…ƒ
        if y < 1911: 
            y += 1911
        return f"{y}-{m:02d}-{d:02d}"
    
    return None

def detect_game_type(filename, df_columns, df_first_row):
    """åš´æ ¼åˆ¤æ–·éŠæˆ²é¡å‹"""
    filename = filename.lower()
    
    # A. å…§å®¹åˆ¤æ–· (æœ€æº–)
    if 'éŠæˆ²åç¨±' in df_columns:
        game_name = str(df_first_row['éŠæˆ²åç¨±'])
        if "539" in game_name: return "ä»Šå½©539"
        if "å¤§æ¨‚é€" in game_name: return "å¤§æ¨‚é€"
        if "å¨åŠ›å½©" in game_name: return "å¨åŠ›å½©"
    
    # B. æª”ååˆ¤æ–·
    for game, cfg in GAME_CONFIG.items():
        for kw in cfg["keywords"]:
            if kw.lower() in filename: return game
            
    return None

def process_and_merge_files(uploaded_files, progress_bar):
    """
    æ ¸å¿ƒå¼•æ“ï¼šè®€å– -> è§£æ -> ç«‹å³åˆä½µè‡³ä¸»è³‡æ–™åº«
    """
    # ç”¨ä¾†æš«å­˜è®€åˆ°çš„æ‰€æœ‰è³‡æ–™
    new_data_buffer = {g: [] for g in GAME_CONFIG.keys()}
    
    total_files = len(uploaded_files)
    
    # 1. éæ­·ä¸Šå‚³çš„æª”æ¡ˆ
    for i, file_obj in enumerate(uploaded_files):
        progress_bar.progress((i + 1) / total_files, text=f"æ­£åœ¨è§£æ: {file_obj.name}")
        
        # è™•ç† ZIP
        if file_obj.name.endswith('.zip'):
            with zipfile.ZipFile(file_obj, 'r') as z:
                z.extractall(DATA_DIR)
            continue # ZIP è§£å£“å¾Œï¼Œä¸‹æ¬¡æƒææœƒè®€åˆ° CSVï¼Œé€™è£¡å…ˆè·³é

        # è™•ç† CSV
        try:
            # å¤šç·¨ç¢¼å˜—è©¦
            try: df = pd.read_csv(file_obj, encoding='cp950', on_bad_lines='skip')
            except: 
                try: df = pd.read_csv(file_obj, encoding='big5', on_bad_lines='skip')
                except: 
                    file_obj.seek(0)
                    df = pd.read_csv(file_obj, encoding='utf-8', on_bad_lines='skip')
            
            # æ¸…ç†æ¬„ä½åç¨± (å»é™¤ç©ºæ ¼)
            df.columns = [str(c).strip().replace(" ", "") for c in df.columns]
            
            if df.empty: continue

            # åˆ¤æ–·é¡å‹
            game_type = detect_game_type(file_obj.name, df.columns, df.iloc[0])
            
            # åªè™•ç†ä¸‰å¤§å½©ç¨®ï¼Œå…¶ä»–è·³é
            if not game_type: continue
            
            cfg = GAME_CONFIG[game_type]
            
            # é–‹å§‹è§£ææ¯ä¸€è¡Œ
            if 'é–‹çæ—¥æœŸ' in df.columns:
                for _, row in df.iterrows():
                    try:
                        # æ—¥æœŸ
                        d_str = parse_date_strict(row['é–‹çæ—¥æœŸ'])
                        if not d_str: continue
                        
                        # è™Ÿç¢¼
                        nums = []
                        for k in range(1, cfg["num_count"] + 1):
                            col_name = f'çè™Ÿ{k}'
                            if col_name in df.columns:
                                nums.append(int(row[col_name]))
                        
                        if len(nums) != cfg["num_count"]: continue
                        
                        # ç‰¹åˆ¥è™Ÿ / ç¬¬äºŒå€
                        sp = []
                        if cfg["has_special"]:
                            if "ç¬¬äºŒå€" in df.columns: sp = [int(row['ç¬¬äºŒå€'])]
                            elif "ç‰¹åˆ¥è™Ÿ" in df.columns: sp = [int(row['ç‰¹åˆ¥è™Ÿ'])]
                            else: sp = [0]
                        
                        # æ’åºä¸»è™Ÿç¢¼
                        nums.sort()
                        
                        # çµ„åˆ (Date, N1...N5/6, SP, Source)
                        entry = [d_str] + nums + sp + ["History_Import"]
                        
                        if len(entry) == len(cfg["cols"]):
                            new_data_buffer[game_type].append(entry)
                            
                    except: continue
                    
        except Exception as e:
            print(f"Error reading {file_obj.name}: {e}")
            continue

    # 2. ç«‹å³åˆä½µè‡³ä¸»è³‡æ–™åº«
    updated_counts = {}
    
    for game, rows in new_data_buffer.items():
        if not rows:
            updated_counts[game] = 0
            continue
            
        cfg = GAME_CONFIG[game]
        db_path = cfg["db_file"]
        
        # è¼‰å…¥ç¾æœ‰ DB
        if os.path.exists(db_path):
            try:
                old_df = pd.read_csv(db_path)
            except:
                old_df = pd.DataFrame(columns=cfg["cols"])
        else:
            old_df = pd.DataFrame(columns=cfg["cols"])
            
        # è½‰æˆ DF
        new_df = pd.DataFrame(rows, columns=cfg["cols"])
        
        # åˆä½µ
        final_df = pd.concat([old_df, new_df], ignore_index=True)
        
        # é—œéµï¼šå»é‡ (ä»¥æ—¥æœŸç‚ºæº–ï¼Œä¿ç•™æœ€å¾Œä¸€ç­†) èˆ‡ æ’åº
        final_df.drop_duplicates(subset=['Date'], keep='last', inplace=True)
        final_df.sort_values(by='Date', ascending=True, inplace=True)
        
        # å­˜æª”
        final_df.to_csv(db_path, index=False)
        updated_counts[game] = len(final_df)
        
    return updated_counts

# --- 5. è®€å– DB (é¡¯ç¤ºç”¨) ---
def load_db(game_name):
    cfg = GAME_CONFIG[game_name]
    if os.path.exists(cfg["db_file"]):
        return pd.read_csv(cfg["db_file"])
    return pd.DataFrame()

# --- 6. çˆ¬èŸ²è£œå–® ---
def crawl_daily(game_name):
    cfg = GAME_CONFIG[game_name]
    url = "https://i539.tw/"
    headers = {'User-Agent': 'Mozilla/5.0'}
    new_rows = []
    try:
        res = requests.get(url, headers=headers, verify=False, timeout=5)
        res.encoding = 'utf-8'
        lines = res.text.split('\n')
        for line in lines:
            if len(line)<10: continue
            match = re.search(r'(\d{4})[\/-](\d{1,2})[\/-](\d{1,2})', line)
            if not match: continue
            d_str = f"{match.group(1)}-{match.group(2).zfill(2)}-{match.group(3).zfill(2)}"
            if d_str < "2025-01-01": continue
            
            clean = line.replace(match.group(0), "")
            all_n = [int(n) for n in re.findall(r'\b\d{1,2}\b', clean)]
            valid_n, sp_n = [], []
            
            if game_name == "ä»Šå½©539": valid_n = sorted([n for n in all_n if 1<=n<=39])[:5]
            elif game_name == "å¤§æ¨‚é€":
                if len(all_n)>=7: 
                    valid_n = sorted([n for n in all_n if 1<=n<=49][:6])
                    sp_n = [all_n[6]] if 1<=all_n[6]<=49 else [0]
            elif game_name == "å¨åŠ›å½©":
                 if len(all_n)>=7:
                     valid_n = sorted([n for n in all_n[:6] if 1<=n<=38])
                     sp_n = [all_n[6]] if 1<=all_n[6]<=8 else [1]

            if len(valid_n) == cfg["num_count"]:
                entry = [d_str] + valid_n + sp_n + ["Web_Crawl"]
                if len(entry) == len(cfg["cols"]): new_rows.append(entry)
    except: pass
    
    if new_rows:
        df_new = pd.DataFrame(new_rows, columns=cfg["cols"])
        if os.path.exists(cfg["db_file"]):
            df_old = pd.read_csv(cfg["db_file"])
            df_final = pd.concat([df_old, df_new], ignore_index=True)
        else: df_final = df_new
        
        df_final.drop_duplicates(subset=['Date'], keep='last', inplace=True)
        df_final.sort_values(by='Date', ascending=True, inplace=True)
        df_final.to_csv(cfg["db_file"], index=False)
        return len(new_rows)
    return 0

# --- 7. é æ¸¬èˆ‡è¦–è¦ºåŒ– ---
def get_ball_html(num, count, is_special=False):
    if is_special: return f'<div class="special-ball">{num:02d}</div>'
    color = "ball-white"
    if count >= 6: color = "ball-gold"
    elif count == 5: color = "ball-red"
    elif count == 4: color = "ball-yellow"
    elif count == 3: color = "ball-blue"
    elif count == 2: color = "ball-green"
    return f'<div class="lottery-ball {color}">{num:02d}</div>'

def render_row(nums, counts, sp=None):
    html = '<div style="display:flex;justify-content:center;flex-wrap:wrap;">'
    for n in nums: html += get_ball_html(n, counts.get(n, 1))
    if sp is not None: html += get_ball_html(sp, 1, True)
    html += '</div>'
    return html

def calc_weights(df, cfg, cols, rng, mode="balanced"):
    mn, mx = rng
    all_range = list(range(mn, mx+1))
    df_hist = df.iloc[:-1]
    freq = pd.Series(df_hist[cols].values.flatten()).value_counts().reindex(all_range, fill_value=0)
    prob_hist = freq / freq.sum()
    
    df_rec = df.tail(30)
    freq_rec = pd.Series(df_rec[cols].values.flatten()).value_counts().reindex(all_range, fill_value=0)
    prob_rec = (freq_rec + 0.1) / (freq_rec.sum() + 1)
    
    # ç‰ˆè·¯
    last_draw = df.iloc[-1][cols].values
    drag = pd.Series(0.0, index=all_range)
    mat = df_hist[cols].values
    for t in last_draw:
        idxs = np.where(mat[:-1] == t)[0]
        n_idxs = idxs + 1
        if len(n_idxs) > 0:
            n_draws = mat[n_idxs]
            c = pd.Series(n_draws.flatten()).value_counts().reindex(all_range, fill_value=0)
            drag = drag.add(c, fill_value=0)
    prob_banlu = drag / drag.sum() if drag.sum() > 0 else pd.Series(1/len(all_range), index=all_range)
    
    if mode == "trend": final = prob_rec * 0.8 + prob_hist * 0.2
    elif mode == "banlu": final = prob_banlu * 0.7 + prob_rec * 0.3
    else: final = prob_rec * 0.4 + prob_hist * 0.3 + prob_banlu * 0.3
    return final / final.sum()

# --- 8. ä»‹é¢ ---
with st.sidebar:
    st.title("ğŸ—„ï¸ çµ•å°æ­¸æª”ä¸­å¿ƒ")
    game = st.selectbox("é¸æ“‡å½©ç¨®", list(GAME_CONFIG.keys()))
    
    st.markdown("---")
    st.subheader("ğŸ“‚ 1. åŒ¯å…¥æ­·å¹´è³‡æ–™ (2007-2025)")
    st.info("è«‹å°‡æ‰€æœ‰ CSV å…¨é¸æ‹–å…¥ä¸‹æ–¹ (ç³»çµ±æœƒè‡ªå‹•éæ¿¾éç›¸é—œæª”æ¡ˆ)")
    uploaded_files = st.file_uploader("CSV/ZIP", accept_multiple_files=True, type=['csv', 'zip'])
    
    if uploaded_files:
        if st.button("ğŸ“¥ å¼·åˆ¶åˆä½µæ­¸æª”"):
            bar = st.progress(0)
            stats = process_and_merge_files(uploaded_files, bar)
            bar.empty()
            st.success("æ­¸æª”å®Œæˆï¼")
            for g, c in stats.items():
                st.write(f"- **{g}**: ç›®å‰å…± {c} ç­†")
            time.sleep(2)
            st.rerun()

    st.markdown("---")
    if st.button(f"ğŸš€ 2. æ¯æ—¥è£œå–® ({game})"):
        with st.spinner("é€£ç·šä¸­..."):
            c = crawl_daily_web(game)
            if c>0: st.success(f"æ›´æ–° {c} ç­†")
            else: st.info("ç„¡æ–°è³‡æ–™")
            st.rerun()

# ä¸»ç•«é¢
cfg = GAME_CONFIG[game]
df = load_db(game)

# CSS
st.markdown("""
<style>
.stApp { background-color: #f0f7f4; background-image: url("https://www.transparenttextures.com/patterns/rice-paper-2.png"); }
</style>
""", unsafe_allow_html=True)

st.title(f"ğŸ¯ {game} æ“ç›¤å®¤")

if df.empty:
    st.error(f"âš ï¸ {game} è³‡æ–™åº«ç‚ºç©ºã€‚")
    st.warning("è«‹åœ¨å·¦å´ **æ­¥é©Ÿ 1** åŒ¯å…¥æ­·å¹´ CSV æª”æ¡ˆã€‚")
else:
    c1, c2, c3 = st.columns(3)
    c1.metric("ç¸½æœŸæ•¸", len(df))
    c2.metric("æœ€æ—©æ—¥æœŸ", df.iloc[0]['Date'])
    c3.metric("æœ€æ–°æ—¥æœŸ", df.iloc[-1]['Date'])
    
    tab1, tab2 = st.tabs(["ğŸ”® é æ¸¬", "ğŸ“‹ æ•¸æ“š"])
    
    with tab1:
        c_l, c_r = st.columns(2)
        tol = c_l.slider("èª¤å·®å€¼", 0.01, 0.5, 0.15, 0.01)
        repeater = c_r.checkbox("é€£èŠ", value=True)
        
        if st.button("ğŸ² é‹ç®—", type="primary"):
            cands = []
            # é æ¸¬åƒæ•¸
            num_cols = [c for c in cfg["cols"] if c.startswith("N")]
            df_n = df[num_cols].apply(pd.to_numeric)
            avg_std = df_n.std(axis=1).mean()
            
            # ç¬¬äºŒå€
            sp_probs = None
            has_z2 = cfg.get("special_is_zone2", False)
            z2_col = "Zw" if has_z2 else ("SP" if cfg["has_special"] else None)
            if z2_col:
                sp_range = cfg.get("special_range", cfg["num_range"])
                sp_probs = calc_weights(df, cfg, [z2_col], sp_range, "trend")
            
            temps = ["balanced", "trend", "banlu"]
            bar = st.progress(0)
            
            for idx, mode in enumerate(temps * 2):
                probs = calc_weights(df, cfg, num_cols, cfg["num_range"], mode)
                nums = probs.index.tolist()
                p_vals = probs.values
                
                found = False
                att = 0
                while not found and att < 5000:
                    sel = sorted(np.random.choice(nums, cfg["num_count"], replace=False, p=p_vals))
                    if repeater:
                        last = df_n.iloc[-1].values
                        r_n = np.random.choice(last)
                        if r_n not in sel: sel[0] = r_n; sel.sort()
                    
                    curr_std = np.std(sel, ddof=1)
                    if abs(curr_std - avg_std) <= tol:
                        sp = None
                        if sp_probs is not None: sp = np.random.choice(sp_probs.index.tolist(), p=sp_probs.values)
                        cands.append({'n': sel, 's': sp, 'e': abs(curr_std - avg_std), 't': mode})
                        found = True
                    att += 1
                bar.progress((idx+1)/6)
            bar.empty()
            st.session_state['res'] = cands
            
        if 'res' in st.session_state:
            res_list = st.session_state['res']
            all_n = []
            for r in res_list: all_n.extend(r['n'])
            ctr = collections.Counter(all_n)
            
            cols = st.columns(3)
            for i, r in enumerate(res_list):
                with cols[i%3]:
                    html = f'<div class="stCard"><b>{r["t"]}</b>'
                    html += '<div class="zone-label">ç¬¬ä¸€å€</div>'
                    html += render_row(r['n'], ctr, None)
                    if r['s']:
                        html += '<div class="zone-label" style="color:red">ç¬¬äºŒå€</div>'
                        html += render_row([], {}, r['s'])
                    html += f'<small>èª¤å·®: {r["e"]:.4f}</small></div>'
                    st.markdown(html, unsafe_allow_html=True)

    with tab2:
        st.dataframe(df.sort_values(by='Date', ascending=False), use_container_width=True)
