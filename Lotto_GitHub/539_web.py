import streamlit as st
import pandas as pd
import numpy as np
import requests
import os
import re
import urllib3
from datetime import datetime
import glob
import time
import zipfile
import altair as alt

# --- 1. ç³»çµ±è¨­å®š ---
st.set_page_config(page_title="å°å½©æ•¸æ“šä¸­å¿ƒ v18.0 (å…¨èƒ½è³‡æ–™åº«)", page_icon="ğŸ¢", layout="wide")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- 2. è³‡æ–™è·¯å¾‘ ---
DATA_DIR = "data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# è‡ªå‹•è§£å£“ ZIP (å¦‚æœæœ‰)
zip_files = glob.glob("*.zip") + glob.glob(os.path.join(DATA_DIR, "*.zip"))
for z_file in zip_files:
    try:
        if zipfile.is_zipfile(z_file):
            # æª¢æŸ¥ data å…§æ˜¯å¦å·²æœ‰ csvï¼Œè‹¥å¤ªå°‘å‰‡è§£å£“
            if len(glob.glob(os.path.join(DATA_DIR, "**", "*.csv"), recursive=True)) < 5:
                with zipfile.ZipFile(z_file, 'r') as zip_ref:
                    zip_ref.extractall(DATA_DIR)
    except: pass

LOG_FILE = os.path.join(DATA_DIR, "prediction_log.csv")

# --- 3. éŠæˆ²è¨­å®š (æ“´å……è‡³å…¨å½©ç¨®) ---
GAME_CONFIG = {
    "ä»Šå½©539": {
        "keywords": ["ä»Šå½©539", "539"],
        "db_file": "db_539.csv",
        "num_count": 5, "num_range": (1, 39), "has_special": False, "enable_predict": True,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "Source"]
    },
    "å¤§æ¨‚é€": {
        "keywords": ["å¤§æ¨‚é€", "Lotto649"],
        "db_file": "db_lotto649.csv",
        "num_count": 6, "num_range": (1, 49), "has_special": True, "enable_predict": True,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "N6", "SP", "Source"]
    },
    "å¨åŠ›å½©": {
        "keywords": ["å¨åŠ›å½©", "SuperLotto"],
        "db_file": "db_super.csv",
        "num_count": 6, "num_range": (1, 38), "has_special": True, "enable_predict": True,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "N6", "Zw", "Source"]
    },
    "3æ˜Ÿå½©": {
        "keywords": ["3æ˜Ÿå½©", "3 Star"],
        "db_file": "db_3star.csv",
        "num_count": 3, "num_range": (0, 9), "has_special": False, "enable_predict": False,
        "cols": ["Date", "D1", "D2", "D3", "Source"]
    },
    "4æ˜Ÿå½©": {
        "keywords": ["4æ˜Ÿå½©", "4 Star"],
        "db_file": "db_4star.csv",
        "num_count": 4, "num_range": (0, 9), "has_special": False, "enable_predict": False,
        "cols": ["Date", "D1", "D2", "D3", "D4", "Source"]
    },
    "39æ¨‚åˆå½©": {
        "keywords": ["39æ¨‚åˆå½©"],
        "db_file": "db_39lotto.csv",
        "num_count": 5, "num_range": (1, 39), "has_special": False, "enable_predict": True,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "Source"]
    },
    "49æ¨‚åˆå½©": {
        "keywords": ["49æ¨‚åˆå½©"],
        "db_file": "db_49lotto.csv",
        "num_count": 6, "num_range": (1, 49), "has_special": False, "enable_predict": True,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "N6", "Source"]
    },
    "è³“æœè³“æœ": {
        "keywords": ["è³“æœè³“æœ", "Bingo"],
        "db_file": "db_bingo.csv",
        "num_count": 20, "num_range": (1, 80), "has_special": True, "enable_predict": False, # è³“æœé‚„æœ‰è¶…ç´šçè™Ÿ
        "cols": ["Date", "Period"] + [f"N{i}" for i in range(1, 21)] + ["Super", "Source"]
    },
    "å¤§æ¨‚é€åŠ é–‹": {
        "keywords": ["åŠ é–‹çé …", "Big Red"],
        "db_file": "db_lotto649_extra.csv",
        "num_count": 6, "num_range": (1, 49), "has_special": False, "enable_predict": False,
        "cols": ["Date", "N1", "N2", "N3", "N4", "N5", "N6", "Source"] # ç°¡åŒ–ç‰ˆ
    }
}

# --- 4. æ™ºæ…§åˆ†é¡èˆ‡è®€å–å¼•æ“ ---

def detect_game_type(filename, df_head):
    """åˆ¤æ–·æª”æ¡ˆå±¬æ–¼å“ªç¨®éŠæˆ²"""
    filename = filename.lower()
    # 1. æª”åå„ªå…ˆ
    for game, cfg in GAME_CONFIG.items():
        for kw in cfg["keywords"]:
            if kw.lower() in filename: return game
    # 2. å…§å®¹åˆ¤æ–·
    if 'éŠæˆ²åç¨±' in df_head.columns:
        val = str(df_head.iloc[0]['éŠæˆ²åç¨±'])
        for game in GAME_CONFIG.keys():
            if game in val: return game
    return None

def process_bulk_files(uploaded_files, progress_bar):
    """è™•ç†ä¸Šå‚³çš„æª”æ¡ˆï¼Œè‡ªå‹•æ­¸æª”"""
    results = {g: 0 for g in GAME_CONFIG.keys()}
    temp_storage = {g: [] for g in GAME_CONFIG.keys()}
    
    total = len(uploaded_files)
    for i, up_file in enumerate(uploaded_files):
        progress_bar.progress((i + 1) / total, text=f"è™•ç†ä¸­: {up_file.name}")
        
        try:
            # è®€å– CSV
            try: df = pd.read_csv(up_file, encoding='cp950', on_bad_lines='skip')
            except: 
                try: df = pd.read_csv(up_file, encoding='big5', on_bad_lines='skip')
                except: 
                    up_file.seek(0)
                    df = pd.read_csv(up_file, encoding='utf-8', on_bad_lines='skip')
            
            df.columns = [str(c).strip() for c in df.columns]
            game_type = detect_game_type(up_file.name, df.head(1))
            if not game_type: continue
            
            cfg = GAME_CONFIG[game_type]
            
            # é‡å°è³“æœåšç‰¹æ®Šè™•ç† (æ¬„ä½å¤š)
            if game_type == "è³“æœè³“æœ":
                for _, row in df.iterrows():
                    try:
                        d_str = pd.to_datetime(str(row['é–‹çæ—¥æœŸ']).strip()).strftime('%Y-%m-%d')
                        period = str(row['æœŸåˆ¥'])
                        nums = [int(row[f'çè™Ÿ{k}']) for k in range(1, 21)]
                        sp = [int(row['è¶…ç´šçè™Ÿ'])] if 'è¶…ç´šçè™Ÿ' in df.columns else [0]
                        entry = [d_str, period] + nums + sp + ["UserUpload"]
                        if len(entry) == len(cfg["cols"]): temp_storage[game_type].append(entry)
                    except: continue
                    
            # ä¸€èˆ¬å½©ç¨®è™•ç†
            else:
                for _, row in df.iterrows():
                    try:
                        d_str = pd.to_datetime(str(row['é–‹çæ—¥æœŸ']).strip()).strftime('%Y-%m-%d')
                        nums = []
                        for k in range(1, cfg["num_count"] + 1):
                            col = f'çè™Ÿ{k}'
                            if col in df.columns: nums.append(int(row[col]))
                        
                        if len(nums) != cfg["num_count"]: continue
                        
                        sp = []
                        if cfg["has_special"]:
                            if "ç¬¬äºŒå€" in df.columns: sp = [int(row['ç¬¬äºŒå€'])]
                            elif "ç‰¹åˆ¥è™Ÿ" in df.columns: sp = [int(row['ç‰¹åˆ¥è™Ÿ'])]
                            else: sp = [0] # é˜²å‘†
                            
                        if cfg["enable_predict"]: nums.sort()
                        
                        entry = [d_str] + nums + sp + ["UserUpload"]
                        if len(entry) == len(cfg["cols"]): temp_storage[game_type].append(entry)
                    except: continue
        except: continue

    # å­˜æª”
    for game, rows in temp_storage.items():
        if rows:
            cfg = GAME_CONFIG[game]
            # å­˜æˆç¨ç«‹æª”æ¡ˆï¼Œé¿å…è·Ÿçˆ¬èŸ²æª”æ‰“æ¶
            new_filename = f"Upload_{game}_{int(time.time())}.csv"
            pd.DataFrame(rows, columns=cfg["cols"]).to_csv(os.path.join(DATA_DIR, new_filename), index=False)
            results[game] += len(rows)
            
    return results

@st.cache_data(show_spinner=False, ttl=60)
def load_all_data(game_name):
    """è®€å–è©²éŠæˆ²çš„æ‰€æœ‰è³‡æ–™"""
    if game_name not in GAME_CONFIG: return pd.DataFrame()
    cfg = GAME_CONFIG[game_name]
    
    # éè¿´æœå°‹æ‰€æœ‰ CSV
    all_files = glob.glob(os.path.join(DATA_DIR, "**", "*.csv"), recursive=True)
    target_files = [f for f in all_files if "prediction_log.csv" not in f]
    
    merged_data = []
    
    for file_path in target_files:
        filename = os.path.basename(file_path)
        # é—œéµå­—ç¯©é¸
        if any(k in filename for k in cfg["keywords"]):
            # è‹¥é¸çš„æ˜¯è³“æœï¼Œå°±åªè®€è³“æœï¼›è‹¥é¸å…¶ä»–ï¼Œæ’é™¤è³“æœä»¥çœè³‡æº
            if game_name != "è³“æœè³“æœ" and "è³“æœ" in filename: continue
            if game_name == "è³“æœè³“æœ" and "è³“æœ" not in filename: continue

            try:
                try: df = pd.read_csv(file_path, encoding='cp950', on_bad_lines='skip')
                except: 
                    try: df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip')
                    except: continue
                
                df.columns = [str(c).strip() for c in df.columns]
                
                # A. å®˜æ–¹æ ¼å¼ CSV (å«ä¸­æ–‡)
                if 'é–‹çæ—¥æœŸ' in df.columns:
                    # ä½¿ç”¨å‰é¢ process_bulk_files é¡ä¼¼é‚è¼¯è§£æï¼Œé€™è£¡ç°¡åŒ–ç›´æ¥è®€å–å·²è½‰å¥½çš„ Upload æª”å„ªå…ˆ
                    # å¦‚æœä½¿ç”¨è€…ç›´æ¥æ”¾å®˜æ–¹åŸå§‹æª”åœ¨ data è£¡ï¼Œé€™è£¡å³æ™‚è§£æ
                    for _, row in df.iterrows():
                        try:
                            d_str = pd.to_datetime(str(row['é–‹çæ—¥æœŸ']).strip()).strftime('%Y-%m-%d')
                            # ... (çœç•¥é‡è¤‡è§£æé‚è¼¯ï¼Œå»ºè­°ä½¿ç”¨è€…é€éåŒ¯å…¥åŠŸèƒ½è½‰æˆæ¨™æº–æ ¼å¼)
                            # é€™è£¡åƒ…æ”¯æ´æ¨™æº–æ ¼å¼è®€å–ï¼Œè‹¥ç‚ºåŸå§‹æª”å»ºè­°å…ˆåŒ¯å…¥
                            pass 
                        except: continue

                # B. æ¨™æº–æ ¼å¼ (æˆ‘å€‘è½‰å­˜å¾Œçš„)
                elif 'Date' in df.columns:
                    # æª¢æŸ¥æ¬„ä½æ˜¯å¦å»åˆ
                    if len(df.columns) == len(cfg["cols"]):
                        merged_data.extend(df.values.tolist())
                    else:
                        # æ¬„ä½ä¸åˆå˜—è©¦ä¿®æ­£ (ä¾‹å¦‚ç¼º Source)
                        valid_cols = [c for c in cfg["cols"] if c in df.columns]
                        temp_df = df[valid_cols].copy()
                        if "Source" not in temp_df.columns: temp_df["Source"] = "Auto"
                        if len(temp_df.columns) == len(cfg["cols"]):
                            merged_data.extend(temp_df.values.tolist())
            except: continue

    if merged_data:
        final_df = pd.DataFrame(merged_data, columns=cfg["cols"])
        # è³“æœè³‡æ–™é‡å¤§ï¼Œå»é‡è¼ƒæ…¢ï¼Œå¯è¦–æƒ…æ³å„ªåŒ–
        final_df.drop_duplicates(subset=['Date'] if game_name!="è³“æœè³“æœ" else ['Date', 'Period'], keep='last', inplace=True)
        final_df.sort_values(by='Date', ascending=True, inplace=True)
        return final_df
    return pd.DataFrame(columns=cfg["cols"])

# --- 5. çˆ¬èŸ²æ›´æ–° ---
def crawl_daily_web(game_name):
    if game_name not in ["ä»Šå½©539", "å¤§æ¨‚é€", "å¨åŠ›å½©"]: return 0
    cfg = GAME_CONFIG[game_name]
    url = "https://i539.tw/"
    headers = {'User-Agent': 'Mozilla/5.0'}
    new_rows = []
    try:
        res = requests.get(url, headers=headers, verify=False, timeout=5)
        res.encoding = 'utf-8'
        lines = res.text.split('\n')
        for line in lines:
            if len(line) < 10: continue
            match = re.search(r'(\d{4})[\/-](\d{1,2})[\/-](\d{1,2})', line)
            if not match: continue
            d_str = f"{match.group(1)}-{match.group(2).zfill(2)}-{match.group(3).zfill(2)}"
            if d_str < "2025-01-01": continue # åªæŠ“ä»Šå¹´çš„
            
            clean = line.replace(match.group(0), "")
            all_n = [int(n) for n in re.findall(r'\b\d{1,2}\b', clean)]
            valid_n, sp_n = [], []
            
            if game_name == "ä»Šå½©539": valid_n = sorted([n for n in all_n if 1<=n<=39])[:5]
            elif game_name == "å¤§æ¨‚é€":
                t = [n for n in all_n if 1<=n<=49]
                if len(t)>=7: valid_n = sorted(t[:6]); sp_n = [t[6]]
            elif game_name == "å¨åŠ›å½©":
                if len(all_n)>=7: valid_n = sorted([n for n in all_n[:6] if 1<=n<=38]); sp_n = [all_n[6]] if 1<=all_n[6]<=8 else [1]
            
            if len(valid_n) == cfg["num_count"]:
                entry = [d_str] + valid_n + sp_n + ["Web_Crawl"]
                if len(entry) == len(cfg["cols"]): new_rows.append(entry)
    except: pass
    
    if new_rows:
        filename = f"Daily_Patch_{game_name}.csv"
        path = os.path.join(DATA_DIR, filename)
        pd.DataFrame(new_rows, columns=cfg["cols"]).to_csv(path, index=False)
        return len(new_rows)
    return 0

# --- 6. ä»‹é¢ ---

with st.sidebar:
    st.title("ğŸ›ï¸ å…¨èƒ½ç¸½æ§å°")
    selected_game = st.selectbox("é¸æ“‡å½©ç¨®", list(GAME_CONFIG.keys()), index=0)
    
    st.markdown("---")
    st.subheader("ğŸ“‚ æ‰¹æ¬¡åŒ¯å…¥è³‡æ–™åº«")
    st.info("å°‡æ‚¨æ‰€æœ‰çš„ CSV æª” (åŒ…å«è³“æœã€3æ˜Ÿã€4æ˜Ÿ...) å…¨éƒ¨æ‹–é€²ä¾†ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†é¡ã€‚")
    
    uploaded_files = st.file_uploader("æ‹–æ›³æª”æ¡ˆè‡³æ­¤", accept_multiple_files=True, type=['csv'])
    if uploaded_files:
        if st.button("ğŸ“¥ é–‹å§‹æ™ºæ…§æ­¸æª”"):
            bar = st.progress(0, text="å•Ÿå‹•ä¸­...")
            res = process_bulk_files(uploaded_files, bar)
            bar.empty()
            st.success("âœ… æ­¸æª”å®Œæˆï¼")
            for g, c in res.items():
                if c > 0: st.write(f"- {g}: +{c} ç­†")
            load_all_data.clear()
            time.sleep(3)
            st.rerun()
            
    st.markdown("---")
    if selected_game in ["ä»Šå½©539", "å¤§æ¨‚é€", "å¨åŠ›å½©"]:
        if st.button(f"ğŸš€ æ›´æ–° {selected_game}"):
            with st.spinner("çˆ¬å–ä¸­..."):
                c = crawl_daily_web(selected_game)
                if c>0: 
                    load_all_data.clear()
                    st.success(f"æ›´æ–° {c} ç­†ï¼")
                    st.rerun()
                else: st.info("ç„¡æ–°è³‡æ–™")

# ä¸»ç•«é¢
cfg = GAME_CONFIG[selected_game]
df = load_all_data(selected_game)

st.header(f"ğŸ“Š {selected_game} è³‡æ–™åº«")

if df.empty:
    st.warning("å°šç„¡è³‡æ–™ã€‚è«‹ä½¿ç”¨å·¦å´åŒ¯å…¥åŠŸèƒ½ã€‚")
else:
    c1, c2, c3 = st.columns(3)
    c1.metric("ç¸½ç­†æ•¸", len(df))
    c2.metric("èµ·", df.iloc[0]['Date'])
    c3.metric("è¨–", df.iloc[-1]['Date'])
    
    tab1, tab2 = st.tabs(["ğŸ“‹ æ•¸æ“šåˆ—è¡¨", "ğŸ”® çµ±è¨ˆé æ¸¬"])
    
    with tab1:
        st.dataframe(df, use_container_width=True, height=600)
        
    with tab2:
        if not cfg["enable_predict"]:
            st.info("æ­¤éŠæˆ²ç‚ºæ•¸å­—æ’åˆ—å‹ï¼Œä¸æä¾›é æ¸¬åŠŸèƒ½ã€‚")
        else:
            st.subheader("ä¸‹æœŸé æ¸¬ (åŸºæ–¼æ­·å²æ•¸æ“š)")
            if st.button("ğŸ² é‹ç®—"):
                num_cols = [c for c in cfg["cols"] if c.startswith("N")]
                df_nums = df[num_cols].apply(pd.to_numeric)
                
                # ç°¡å–®çµ±è¨ˆæ¬Šé‡
                vals = df_nums.values.flatten()
                freq = pd.Series(vals).value_counts().sort_index()
                mn, mx = cfg["num_range"]
                for i in range(mn, mx+1): 
                    if i not in freq: freq[i] = 0
                
                w = freq.values / freq.values.sum()
                nums = freq.index.tolist()
                
                res = []
                for _ in range(5):
                    s = sorted(np.random.choice(nums, cfg["num_count"], replace=False, p=w))
                    res.append(s)
                
                cols = st.columns(5)
                for i, (c, r) in enumerate(zip(cols, res)):
                    c.success(f"ç¬¬ {i+1} çµ„")
                    c.code(str(r))